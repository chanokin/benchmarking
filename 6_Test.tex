\section{Case Studies}
\label{sec:test}
In this section, we present two recognition systems working on the Poissonian subset as examples of using the NE15-MNIST dataset.
They provide possible concerns of creating benchmark tests, such as, using unified SNN description language, standard learning rules and neural models.
Thus, in order to apply the same benchmarking system on various simulators both software and hardware.
Evaluation on such a benchmark test is still under investigation, the case studies only give an attempt.

\subsection{Case Study I}
It is a simple two-layered network where the input neurons receive Poissonian presented spike trains from the dataset and forwards the connections to the decision neurons.
During the training, each decision neuron is triggered by a teaching neuron while the weights of the synaptic connections of the input neurons and the decision neuron are modulated with the standard STDP learning rule, see Fig~\ref{Fig:train}.
The model utilises Leaky-Integrate-and-Fire (LIF) neurons, and the parameters were all with biological means, see the listed values in Table~\ref{tbl:pynnSetting}.
The model is described with PyNN and the code is published in the same github repository.
Consequently, the benchmark model can be directly run on different SNN simulators as long as PyNN is supported.
Besides, any modification on neuron or learning model is not required since only standard models are used.

\begin{table}[hbbp]
\centering
\caption{\label{tbl:pynnSetting}Parameter setting for the current-based LIF neurons using PyNN}
\bgroup
\def\arraystretch{1.1}
  \begin{tabular}{c|c|c}
  %\hline
  Type & IF\_curr\_exp & Units\\
  \hline
  cm & 0.25 & nF	\\
  %\hline
  tau\_m & 20.0 & ms\\
  %\hline
  tau\_refrac & 2.0 & ms\\
  %\hline
  tau\_syn\_E & 1.0 & ms\\
  %\hline
  tau\_syn\_I & 1.0 & ms\\
  %\hline
  v\_reset & -70.0 & mV\\
  %\hline
  v\_rest & -65.0 & mV\\
  %\hline
  v\_thresh & -50.0 & mV\\
  %\hline
  \end{tabular}
\egroup
\end{table}

\begin{figure}[hbt!]
	\centering
	\subfloat[Training model of a single decision neuron.]{
		\label{Fig:train}
		\includegraphics[width=0.48\textwidth]{images/training.pdf}
		} \\

	\centering
	
	\subfloat[Testing model of the spiking neural network.]{
		\label{Fig:test}
		\includegraphics[width=0.48\textwidth]{images/testing.pdf}
		}
		
	\caption{The training and testing model of the two-layered spiking neural network.}
	\label{fig:model}
\end{figure} 



Both the training and testing exploited the Poissonian subset of the NE15-MNIST dataset.
Because different simulators generate random Poissonian spike trains with various mechanisms, languages and codes, using the same dataset is able to evaluate performance of these simulators without the interference by the non-unified input.
In terms of this case study, the performance of the model was evaluated with both software simulation (on NEST~[\cite{gewaltig2007nest}]) and hardware implementation (on SpiNNaker). 

%\subsection{Description of the data used}
\subsubsection{Training}

There are two layers in the neural network model.
And 28$\times$28 input neurons fully connected to 100 output neurons.
Each output neuron represented a trained template of a digit.
Thus there were 10 templates for each digit.
The firing rate of the input neurons were assigned linearly according to their intensities and normalised with a total firing rate of 2000~$Hz$.
The training set of 60000 hand written digits were firstly classified into 100 classes, 10 classes per digit, using K-means clusters.
Every image was presented 300~$ms$ during training and at the same time a teaching signal of 50~$Hz$ was conveyed to the responding output neuron (1 out of 100) to trigger the learning, see Fig~\ref{Fig:train}.
The trained weights were plotted in align with the input image size in Fig~\ref{Fig:test}.
%\begin{figure}[hbt!]
%	\centering
%	\includegraphics[width=0.48\textwidth]{images/weight_r.pdf}
%	\caption{Trained weights of the synapses from input layer to output neurons.}
%	\label{Fig:weight}
%\end{figure}  



\subsubsection{Testing}
The weights were normalised after training and applied to the same network.
And weak weights (=0) were set to inhibitory connections with an identical strength.
%The output neurons inhibited all the other neurons as a winner take all circuit.
The feed=forward testing network is shown in Fig~\ref{Fig:test}.
Poissonion spike trains are generated with input neurons and conveyed through trained synaptic connections to the decision neurons.
Every testing image was presented 1 second to the network, and the output neuron with the highest firing rate decides.
The accuracy of the recognition reached 82.42\%.%83.14\%.
The recording of the output neurons of a test sequence of digits (4, 1, 1, 0, 9, 3, 1, 9, 4, 6) was shown in the raster plot (Fig~\ref{Fig:output}).
Fig~\ref{Fig:test}.

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.48\textwidth]{images/test300-301.pdf}
	\caption{A raster plot of test of a digits sequence.}
	\label{Fig:output}
\end{figure} 
\subsubsection{Evaluation}

\subsection{[Evangelos Stromatias]Case Study II}
network topology 784-500-500-10. mention that its offline trained and presented in previous work. mention minitaur. mention that we are going to investigate how the precision affects the classification accuracy.

\subsubsection{Training}
\citet{10.3389/fnins.2013.00178}
\subsubsection{Testing}
After the training process the trained synaptic weights can be used in a spiking neural network which consists of LIF neurons with delta-current synapses. Table~\ref{Tab:NeuralParams} shows the LIF parameters used in the simulations.

\begin{table}%[!t]
\textbf{\refstepcounter{table}\label{Tab:NeuralParams} Table \arabic{table}.}{ Default parameters of the Leaky Integrate-and-Fire Model used in simulations.}

\processtable{}
{\begin{tabular}{lllll}\toprule
Parameters & Values & Units \\\midrule
$\tau_{m}$ 		 & 5.0 & s  \\
$T_{\mathrm{refract}}$ & 2.0 & ms \\
%$V_{\mathrm{init}}$ 		 & 0.0 & mV\\
$V_{\mathrm{reset}}$ 		 & 0.0 & mV \\
$V_{\mathrm{thresh}}$ 		 & 1.0 & mV \\
\end{tabular}}{}
\end{table}


The pixels of each MNIST digit from the testing set are converted into Poisson spike trains with a rate proportional to the intensity of their pixel, while their firing rates are scaled so that the total firing rate of the input population is constant \citep{10.3389/fnins.2013.00178}.

 
Table~\ref{tab:casimulators} presents a comparison of the classification accuracies (CA) between the rate-based implementation in MATLAB using the Siegert neurons, Brian \citep{} a software spiking neural network simulator, and SpiNNaker. The default fixed-point weight precision for SpiNNaker is 22 bits, 6 for the integer part and 16 for the fractional part (Q6.16) \citep{}.





\subsubsection{Evaluation}

%Investigate CA as a function of weight precision
%and input firing rates for neuromorphic plaforms 
%verify brian results with spinnaker for a particular
%weight precision.

Neuromorphic platforms may have limited hardware resources to store the synaptic weights \citep{Schemmel_etal10,Merolla08082014}. In order to investigate how the precision of the weights affect the classification accuracy (CA) of a spiking DBN the double floating point weights of the offline trained network were converted to different fixed-point representations. The following notation will be used throughout this paper, Q\textit{m.f}, where \textit{m} signifies the number of bits for the integer part (including the sign bit) and \textit{f} the number of bits used for the fractional part.

Figure~\textbf{[WILLADDFIGURE]} shows the effect of reduced weight bit precision on the CA for different input firing rates on the Brian simulator. To validate the results of the software simulator a simulation ran on SpiNNaker for a weight resolution of Q3.8. SpiNNaker achieved a CA of 94.94\% when 1500~Hz was used for the input population \citep{SpinnakerDBN2015,iscasSpinnakerAcceptedDemo}. Brian for the same firing rates and weight precision achieved a CA of 94.955\%. Results are summarised in Table~\ref{tab:casimulators}   


\begin{table}[h]
\caption{Classification accuracy (CA) of the same DBN running on different platforms.}
\begin{center}
\begin{tabular} {|c|c|c|}
    \hline
    \multicolumn{1}{|c|}{\textbf{Simulator}}
    & \multicolumn{1}{|c|}{\textbf{CA (\%)}}
    & \multicolumn{1}{|c|}{\textbf{Weight Precision}} \\
    \hline
    Matlab & 96.06 & Double floating point\\
    Brian & 95.00 & Double floating point\\
    Brian & 94.955 & Q3.8\\
    SpiNNaker & 94.94 & Q3.8\\
    \hline
\end{tabular}
\label{tab:casimulators}
\end{center}
\end{table}

%Moreover, the difference between the software simulation that utilises double floating-point
%351 weights and SpiNNaker with Q3.8 fixed-point weights is 0.06%, which is in agreement with a previous
%352 study (Stromatias et al., 2015b).

\citet{} \textit{showed that spiking DBN can tolerate input 
up to 60\% for weight precision down to Q3.2, while a novel offline learning rule that }

%CA and latency as a function of input spikes per sec
%both brian and use spinnaker to validate results

An additional experiment was conducted to investigate the classification latency, which is the time passed between the first input spike and the first output spike, and the CA as a function of the total number of input spikes per second. The input rates were varied from 500~Hz to 2000~Hz. Results can be seen in Figure~\ref{Fig:brianLatency}. Simulations ran in Brian for all 10,000 MNIST digits from the training set and for 4 trials. Figure~\ref{Fig:spinnLatency1500hz} shows a histogram of the classification latencies on SpiNNaker when the input rates are 1500~Hz. The mean classification latency for the particular spiking DBN on SpiNNaker is 16~ms which is identical to the Brian simulation seen in Figure~\ref{Fig:brianLatency}.


\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.48\textwidth]{images/evan/latencyCAfiringrate.pdf}
	\caption{Mean classification latency and classification accuracy as a function of the input spikes per second for the spiking DBN. Results are averaged over 4 trials, error bars show standard deviations.}
	\label{Fig:brianLatency}
\end{figure} 



\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.48\textwidth]{images/evan/classlatencyIJCNN1500hz.pdf}
	\caption{Histogram of the classification latencies for the MNIST digits of the testing set when the input rates are set to 1500 Hz. The mean classification latency of the spiking DBN on SpiNNaker is 16 ms.}
	\label{Fig:spinnLatency1500hz}
\end{figure} 

%Mention power consumption and compare against an
%FPGA implementation on the identical network

Finally, this particular spiking DBN ran on a single SpiNNaker chip and dissipated less than 0.3~W when 2000 spikes per second per digit were used, Figure~\textbf{[ADD FIGURE]}. The identical network ran on Minitaur \citep{}, an event-driven FPGA implementation, and consumed 1.5~W when 1000 spikes per image were used.  


%
%To investigate how the precision of the weights of an offline trained spiking DBN mapped 
%
%investigate how the weight precision and input firing rates affect the CA. 
%
%how input rates affect the classification latency
%
%results from spinnaker 
%table with CA
%latency from spinnaker
%
%
%\begin{figure}[hbt!]
%	\centering
%	\includegraphics[width=0.48\textwidth]{images/evan/meanCAvsLatencyvsFiringrate_7hlayer.pdf}
%	\caption{Classification accuracy as a function of the input firing rates.}
%	\label{Fig:rateVSca}
%\end{figure} 
