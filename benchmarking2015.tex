%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is just a template to use when submitting manuscripts to Frontiers, it is not mandatory to use frontiers.cls nor frontiers.tex  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[pdftex]{bioinfo}
\usepackage{subfig}
\usepackage{array}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{mathptmx}
\usepackage{acronym}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[colorlinks]{hyperref} % in order to operate correctly, hyperref must be the last package declared
\usepackage{multirow}
\usepackage{makecell}
\usepackage{mathptmx}
\usepackage{amsmath}
%define some own functions
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}} 
\def\D{\mathrm{d}}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\pagestyle{empty}


\hypersetup{
  hypertexnames=true, 
  linkcolor=blue,anchorcolor=black,citecolor=blue,urlcolor=blue
}



\newenvironment{equationexp}[1]% Environment for explaining equation variables
{\begin{list}{}%
{\setlength{\leftmargin}{#1}}%
  \item[]%
}
{\end{list}}


\DeclareGraphicsExtensions{.jpg,.pdf,.mps,.png}
\graphicspath{{./images/}} % PUT ALL PDF/JPG/PNG FIGURES IN THIS SUBDIR

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

%Commands useful for the review
\newcommand{\revised}[1]{{\color{red} #1}}
\newcommand{\SC}[1]{{\color{red} \textbf{SC: } #1}}


\setlength{\abovecaptionskip}{5pt}
\setlength{\belowcaptionskip}{5pt}

\copyrightyear{2015}
\pubyear{2015}


%%%%%
%\documentclass{frontiersENG} % for Engineering articles
%%\documentclass{frontiersSCNS} % for Science articles
%%\documentclass{frontiersMED} % for Medicine articles
%
%\usepackage{url,lineno}
%\usepackage{epstopdf}
%%\IEEEoverridecommandlockouts
%\usepackage{graphicx}
%\usepackage{subfigure}
%\usepackage{xr-hyper}
%\usepackage{hyperref}
%\linenumbers
%
%% Leave a blank line between paragraphs in stead of using \\
%
%\copyrightyear{}
%\pubyear{}

%%%%%%
%\def\journal{NEUROMORPHIC ENGINEERING}%%% write here for which journal %%%
%\def\DOI{}
%\def\articleType{Research Article}
%\def\keyFont{\fontsize{8}{11}\helveticabold }
\def\firstAuthorLast{Qian Liu {et~al.}} %use et al only if is more than 1 author
%\def\Authors{Qian Liu, Garibaldi Pineda Garcia, Evangelos Stromatias, Teresa Gotarredona, and Steve Furber}
\def\Authors{Qian~Liu\,$^{1,*}$, Garibaldi~Pineda~García\,$^{1}$, Evangelos~Stromatias\,$^{1}$, Teresa~Gotarredona\,$^{2}$, and Steve~Furber\,$^{1}$}
% Affiliations should be keyed to the author's name with superscript numbers and be listed as follows: Laboratory, Institute, Department, Organization, City, State abbreviation (USA, Canada, Australia), and Country (without detailed address information such as city zip codes or street names).
% If one of the authors has a change of address, list the new address below the correspondence details using a superscript symbol and use the same symbol to indicate the author in the author list.
%\def\Address{SpiNNaker, Advanced Processor Technologies Research Group, School of Computer Science, University of Manchester, Manchester, United Kingdom}
\def\Address{$^{1}$SpiNNaker, Advanced Processor Technologies Research Group, School of Computer Science, University of Manchester, Manchester, United Kingdom\\
$^{2}$Instituto de Microelectrónica de Sevilla (IMSE-
CNM-CSIC), Sevilla, Spain }
%% The Corresponding Author should be marked with an asterisk
%% Provide the exact contact address (this time including street name and city zip code) and email of the corresponding author
\def\corrAuthor{Qian Liu}
\def\corrAddress{SpiNNaker, Advanced Processor Technologies Research Group, School of Computer Science, The University of Manchester, Oxford Road, Manchester, M13 9PL, United Kingdom}
\def\corrEmail{qianl.liu-3@manchester.ac.uk}
%
%% \color{FrontiersColor} Is the color used in the Journal name, in the title, and the names of the sections
%

\begin{document}
\firstpage{1}

\title[Benchmarking Spike-Based Visual Recognition: a Dataset and Evaluation]{Benchmarking  Spike-Based Visual Recognition:\\ a Dataset and Evaluation}
\author[\firstAuthorLast ]{\Authors}
\address{\Address}
%\correspondance{}
\history{}

\editor{}


\maketitle
\begin{abstract}
To gain a better understanding of the brain and build biologically-inspired computers, increasing attention is being paid to research into spike-based neural computation.
Within the field, the visual pathway and its hierarchical organisation have been extensively studied within the primate brain.
Spiking Neural Networks (SNNs) inspired by the understanding of observed biological structure and functions have been successfully applied to visual recognition/classification tasks.
A new series of vision benchmarks for spike-based neural processing are now needed to quantitatively measure progress within this rapidly advancing field.
We propose that a large dataset of spike-based visual stimuli is needed to provide a baseline for comparisons.
Furthermore a complementary evaluation methodology is also crucial to assess the accuracy and efficiency of an algorithm.

First of all, an initial NE (Neuromorphic Engineering) dataset of input stimuli based on standard computer vision benchmarks consisting of %facial images (FERET database) and 
digits (MNIST database) is presented according to the current research on spike-based image recognition.
Within this dataset, all images are centre aligned and with similar scale.
We describe how we intend to expand this dataset to fulfil the needs of upcoming research problems.
For instance, the data should provide cases to measure position-, scale-, and viewing-angle invariance.
The data will be in Address-Event Representation (AER) format which is well-applied in neuromorphic engineering field unlike conventional images.
These spike trains are produced by various techniques: rate-based Poisson spike generation, rank order encoding and recorded output from a silicon retina with both flashing and oscillating input stimuli.
An evaluation methodology is also presented which describes how to consistently assess the accuracy, speed, efficiency and cost of an algorithm working with the dataset.
Finally, we provide a baseline for comparison based on a proposed SNN's performance on the dataset.
The network is trained on-line using the Spike Timing Dependent Plasticity (STDP) learning rule on a massive-parallel neuromorphic simulator, e.g. SpiNNaker.

With this benchmark we hope to (1) promote meaningful comparison among algorithms in the field of neural computation, (2) allow comparison with conventional image recognition methods, (3) provide an assessment of the state of the art in spike-based visual recognition, and (4) help researchers identify future directions and advance the field.

\tiny
\section{Keywords:} Benchmarking, Neuromorphic Engineering, Real-Time, Spiking Neural Networks, Vision
%All article types: you may provide up to 8 keywords; at least 5 are mandatory.
\end{abstract}

Outline:
\begin{itemize}
	\item present a dataset
	\item evaluate models on the dataset(SW/HW)
	\item examples of using the dataset and evaluation
\end{itemize}
%\label{sec:intro}
\input{1_Introduction.tex}
\input{2_Relatework.tex}
\input{3_Guide.tex}
\input{4_Database.tex}
\input{5_Evaluate.tex}
\input{6_Test.tex}
\input{7_Conclusion.tex}
\section*{Acknowledgments}
The work presented in this paper is largely inspired on discussions carried out at the 2015 Workshops on Neuromorphic Cognition Engineering in CapoCaccia.
The authors would like to thank the organisers and the sponsors.
The SpiNNaker project is supported by the Engineering and Physical Science Research Council (EPSRC grant EP/4015740/1), the EU Flagship Human Brain Project (FP7-604102), and also by ARM and Silistix.
The authors thank the support of these sponsors and industrial partners.
\bibliographystyle{frontiersinSCNS&ENG} % for Science and Engineering articles
%\bibliographystyle{frontiersinMED} % for Medicine articles

\bibliography{ref,rank-ordered,hw-ind-eval,hw-dep-eval}

\end{document}