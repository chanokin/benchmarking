@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {0018-9219},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	keywords = {2D shape variability, backpropagation, back-propagation, character recognition, cheque reading, complex decision surface synthesis, convolution, convolutional neural network character recognizers, document recognition, document recognition systems, Feature extraction, field extraction, gradient-based learning, gradient based learning technique, graph transformer networks, GTN, handwritten character recognition, handwritten digit recognition task, hidden Markov models, high-dimensional patterns, language modeling, machine learning, Multi-layer neural network, multilayer neural networks, multilayer perceptrons, multimodule systems, Neural networks, optical character recognition, Optical character recognition software, Optical computing, Pattern Recognition, performance measure minimization, Principal component analysis, segmentation recognition},
	pages = {2278--2324},
	file = {IEEE Xplore Abstract Record:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/RDDSDJHU/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/G3CT5B75/Lecun et al. - 1998 - Gradient-based learning applied to document recogn.pdf:application/pdf}
}
@inproceedings{deng_imagenet:_2009,
	title = {{ImageNet}: {A} large-scale hierarchical image database},
	shorttitle = {{ImageNet}},
	doi = {10.1109/CVPR.2009.5206848},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	booktitle = {{IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, 2009. {CVPR} 2009},
	author = {Deng, Jia and Dong, Wei and Socher, R. and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	month = jun,
	year = {2009},
	keywords = {computer vision, Explosions, Image databases, ImageNet database, image resolution, image retrieval, Information retrieval, Internet, large-scale hierarchical image database, large-scale ontology, Large-scale systems, multimedia computing, multimedia data, Multimedia databases, Ontologies, ontologies (artificial intelligence), Robustness, Spine, subtree, trees (mathematics), very large databases, visual databases, wordNet structure},
	pages = {248--255},
	file = {IEEE Xplore Abstract Record:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/TFFAKIMS/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/QMNG4F75/Deng et al. - 2009 - ImageNet A large-scale hierarchical image databas.pdf:application/pdf}
}

@inproceedings{liu_recognizing_2009,
	title = {Recognizing realistic actions from videos \#x201C;in the wild \#x201D;},
	doi = {10.1109/CVPR.2009.5206744},
	abstract = {In this paper, we present a systematic framework for recognizing realistic actions from videos “in the wild”. Such unconstrained videos are abundant in personal collections as well as on the Web. Recognizing action from such videos has not been addressed extensively, primarily due to the tremendous variations that result from camera motion, background clutter, changes in object appearance, and scale, etc. The main challenge is how to extract reliable and informative features from the unconstrained videos. We extract both motion and static features from the videos. Since the raw features of both types are dense yet noisy, we propose strategies to prune these features. We use motion statistics to acquire stable motion features and clean static features. Furthermore, PageRank is used to mine the most informative static features. In order to further construct compact yet discriminative visual vocabularies, a divisive information-theoretic algorithm is employed to group semantically related features. Finally, AdaBoost is chosen to integrate all the heterogeneous yet complementary features for recognition. We have tested the framework on the KTH dataset and our own dataset consisting of 11 categories of actions collected from YouTube and personal videos, and have obtained impressive results for action recognition and action localization.},
	booktitle = {{IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, 2009. {CVPR} 2009},
	author = {Liu, Jingen and Luo, Jiebo and Shah, M.},
	month = jun,
	year = {2009},
	keywords = {action localization, AdaBoost, cameras, computer vision, Feature extraction, Humans, image motion analysis, information-theoretic algorithm, informative static features, KTH dataset, motion features, Motion pictures, motion statistics, PageRank, personal videos, realistic action recognition, Shape, spatiotemporal phenomena, unconstrained videos, Videos, video signal processing, visual vocabularies, Vocabulary, YouTube},
	pages = {1996--2003},
	file = {IEEE Xplore Abstract Record:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/DVK7SNJD/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/7VFBCHUQ/Liu et al. - 2009 - Recognizing realistic actions from videos #x201C\;i.pdf:application/pdf}
}

@article{lin_microsoft_2014,
	title = {Microsoft {COCO}: {Common} {Objects} in {Context}},
	shorttitle = {Microsoft {COCO}},
	url = {http://arxiv.org/abs/1405.0312},
	abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
	urldate = {2015-06-09},
	journal = {arXiv:1405.0312 [cs]},
	author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
	month = may,
	year = {2014},
	note = {arXiv: 1405.0312},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1405.0312 PDF:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/EM38WHHN/Lin et al. - 2014 - Microsoft COCO Common Objects in Context.pdf:application/pdf;arXiv.org Snapshot:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/84JJU8BA/1405.html:text/html}
}

@article{la2008response,
  title={The response of cortical neurons to in vivo-like input current: theory and experiment},
  author={La Camera, Giancarlo and Giugliano, Michele and Senn, Walter and Fusi, Stefano},
  journal={Biological cybernetics},
  volume={99},
  number={4-5},
  pages={279--301},
  year={2008},
  publisher={Springer}
}

@article{siegert1951first,
  title={On the first passage time probability problem},
  author={Siegert, Arnold JF},
  journal={Physical Review},
  volume={81},
  number={4},
  pages={617},
  year={1951},
  publisher={APS}
}

@article{burkitt2006review,
  title={A review of the integrate-and-fire neuron model: I. Homogeneous synaptic input},
  author={Burkitt, Anthony N},
  journal={Biological cybernetics},
  volume={95},
  number={1},
  pages={1--19},
  year={2006},
  publisher={Springer}
}


@inproceedings{delbruck2008frame,
  title={Frame-free dynamic digital vision},
  author={Delbruck, Tobi},
  booktitle={Proceedings of Intl. Symp. on Secure-Life Electronics, Advanced Electronics for Quality Life and Society},
  pages={21--26},
  year={2008}
}

@article{serrano-gotarredona_128_2013,
	title = {A 128$\times $128 1.5\% {Contrast} {Sensitivity} 0.9\% {FPN} 3{$\mu$s} {Latency} 4 {mW} {Asynchronous} {Frame}-{Free} {Dynamic} {Vision} {Sensor} {Using} {Transimpedance} {Preamplifiers}},
	volume = {48},
	issn = {0018-9200},
	doi = {10.1109/JSSC.2012.2230553},
	abstract = {Dynamic Vision Sensors (DVS) have recently appeared as a new paradigm for vision sensing and processing. They feature unique characteristics such as contrast coding under wide illumination variation, micro-second latency response to fast stimuli, and low output data rates (which greatly improves the efficiency of post-processing stages). They can track extremely fast objects (e.g., time resolution is better than 100 kFrames/s video) without special lighting conditions. Their availability has triggered a new range of vision applications in the fields of surveillance, motion analyses, robotics, and microscopic dynamic observations. One key DVS feature is contrast sensitivity, which has so far been reported to be in the 10-15\% range. In this paper, a novel pixel photo sensing and transimpedance pre-amplification stage makes it possible to improve by one order of magnitude contrast sensitivity (down to 1.5\%) and power (down to 4 mW), reduce the best reported FPN (Fixed Pattern Noise) by a factor of 2 (down to 0.9\%), while maintaining the shortest reported latency (3 μs) and good Dynamic Range (120 dB), and further reducing overall area (down to 30 × 31 μm per pixel). The only penalty is the limitation of intrascene Dynamic Range to 3 decades. A 128 × 128 DVS test prototype has been fabricated in standard 0.35 μm CMOS and extensive experimental characterization results are provided.},
	number = {3},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Serrano-Gotarredona, T. and Linares-Barranco, B.},
	month = mar,
	year = {2013},
	keywords = {Address-event-representation, Arrays, asynchronous frame-free DVS, asynchronous frame-free dynamic vision sensor, CMOS image sensors, CMOS process, contrast coding, contrast sensitivity, Dynamic range, dynamic vision sensor, event-based vision, fixed pattern noise, FPN, frame-free vision sensor, high-speed vision, illumination variation, Lighting, lighting conditions, magnitude contrast sensitivity, microscopic dynamic observations, microsecond latency response, motion analyses, operational amplifiers, pixel photosensing, power 4 mW, preamplifiers, robotics, Robot sensing systems, Sensitivity, size 0.35 mum, temporal contrast retina, time 3 mus, transimpedance preamplification stage, transimpedance preamplifiers, Transistors, vision sensor, Voltage control},
	pages = {827--838},
	file = {IEEE Xplore Abstract Record:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/28N6SMEN/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/liuq/.mozilla/firefox/m2i8ko12.default/zotero/storage/5RB3NFAK/Serrano-Gotarredona and Linares-Barranco - 2013 - A 128 128 1.5% Contrast Sensitivity 0.9% FPN 3 #x0.pdf:application/pdf}
}
@article{davison2008pynn,
  title={PyNN: a common interface for neuronal network simulators},
  author={Davison, Andrew P and Br{\"u}derle, Daniel and Eppler, Jochen and Kremkow, Jens and Muller, Eilif and Pecevski, Dejan and Perrinet, Laurent and Yger, Pierre},
  journal={Frontiers in neuroinformatics},
  volume={2},
  year={2008},
  publisher={Frontiers Research Foundation}
}
@book{squire1998findings,
  title={Findings and current opinion in cognitive neuroscience},
  author={Squire, Larry R and Kosslyn, Stephen Michael},
  year={1998},
  publisher={MIT Press}
}
@article{gewaltig2007nest,
  title={NEST (neural simulation tool)},
  author={Gewaltig, Marc-Oliver and Diesmann, Markus},
  journal={Scholarpedia},
  volume={2},
  number={4},
  pages={1430},
  year={2007}
}
@article{furber2007neural,
	title={Neural systems engineering},
	author={Furber, Steve and Temple, Steve},
	journal={Journal of the Royal Society interface},
	volume={4},
	number={13},
	pages={193--206},
	year={2007},
	publisher={The Royal Society}
}
@article{lichtsteiner2008128,
	title={A 128$\times$ 128 120 dB 15 $\mu$s latency asynchronous temporal contrast vision sensor},
	author={Lichtsteiner, Patrick and Posch, Christoph and Delbruck, Tobi},
	journal={Solid-State Circuits, IEEE Journal of},
	volume={43},
	number={2},
	pages={566--576},
	year={2008},
	publisher={IEEE}
}
@article{goodman2008brian,
	title={Brian: a simulator for spiking neural networks in Python},
	author={Goodman, Dan and Brette, Romain},
	journal={Frontiers in neuroinformatics},
	volume={2},
	year={2008},
	publisher={Frontiers Research Foundation}
}
@article{furber2013overview,
	title={Overview of the spinnaker system architecture},
	author={Furber, Steve B and Lester, David R and Plana, Luis and Garside, Jim D and Painkras, Eustace and Temple, Sally and Brown, Andrew D and others},
	journal={Computers, IEEE Transactions on},
	volume={62},
	number={12},
	pages={2454--2467},
	year={2013},
	publisher={IEEE}
}
@inproceedings{schemmel2010wafer,
	title={A wafer-scale neuromorphic hardware system for large-scale neural modeling},
	author={Schemmel, Johannes and Bruderle, D and Grubl, A and Hock, Matthias and Meier, Karlheinz and Millner, Sebastian},
	booktitle={Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on},
	pages={1947--1950},
	year={2010},
	organization={IEEE}
}
@article{moradi2014event,
	title={An event-based neural network architecture with an asynchronous programmable synaptic memory},
	author={Moradi, Saber and Indiveri, Giacomo},
	journal={Biomedical Circuits and Systems, IEEE Transactions on},
	volume={8},
	number={1},
	pages={98--107},
	year={2014},
	publisher={IEEE}
}
@article{felleman1991distributed,
	title={Distributed hierarchical processing in the primate cerebral cortex},
	author={Felleman, Daniel J and Van Essen, David C},
	journal={Cerebral cortex},
	volume={1},
	number={1},
	pages={1--47},
	year={1991},
	publisher={Oxford Univ Press}
}
@article{prado2005two,
	title={Two cortical systems for reaching in central and peripheral vision},
	author={Prado, J{\'e}r{\^o}me and Clavagnier, Simon and Otzenberger, H{\'e}lene and Scheiber, Christian and Kennedy, Henry and Perenin, Marie-Th{\'e}r{\`e}se},
	journal={Neuron},
	volume={48},
	number={5},
	pages={849--858},
	year={2005},
	publisher={Elsevier}
}
@article{goodale1992separate,
	title={Separate visual pathways for perception and action},
	author={Goodale, Melvyn A and Milner, A David},
	journal={Trends in neurosciences},
	volume={15},
	number={1},
	pages={20--25},
	year={1992},
	publisher={Elsevier}
}
@article{dicarlo2012does,
	title={How does the brain solve visual object recognition?},
	author={DiCarlo, James J and Zoccolan, Davide and Rust, Nicole C},
	journal={Neuron},
	volume={73},
	number={3},
	pages={415--434},
	year={2012},
	publisher={Elsevier}
}
@article{serre2007robust,
	title={Robust object recognition with cortex-like mechanisms},
	author={Serre, Thomas and Wolf, Lior and Bileschi, Stanley and Riesenhuber, Maximilian and Poggio, Tomaso},
	journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	volume={29},
	number={3},
	pages={411--426},
	year={2007},
	publisher={IEEE}
}

@article{riesenhuber1999hierarchical,
	title={Hierarchical models of object recognition in cortex},
	author={Riesenhuber, Maximilian and Poggio, Tomaso},
	journal={Nature neuroscience},
	volume={2},
	number={11},
	pages={1019--1025},
	year={1999},
	publisher={Nature Publishing Group}
}

@article{fu_spiking_2012,
	title = {A {Spiking} {Neural} {Network} {Based} {Cortex}-like {Mechanism} and {Application} to {Facial} {Expression} {Recognition}},
	volume = {2012},
	issn = {1687-5265},
	url = {http://dx.doi.org/10.1155/2012/946589},
	doi = {10.1155/2012/946589},
	abstract = {In this paper, we present a quantitative, highly structured cortex-simulated model, which can be simply described as feedforward, hierarchical simulation of ventral stream of visual cortex using biologically plausible, computationally convenient spiking neural network system. The motivation comes directly from recent pioneering works on detailed functional decomposition analysis of the feedforward pathway of the ventral stream of visual cortex and developments on artificial spiking neural networks (SNNs). By combining the logical structure of the cortical hierarchy and computing power of the spiking neuron model, a practical framework has been presented. As a proof of principle, we demonstrate our system on several facial expression recognition tasks. The proposed cortical-like feedforward hierarchy framework has the merit of capability of dealing with complicated pattern recognition problems, suggesting that, by combining the cognitive models with modern neurocomputational approaches, the neurosystematic approach to the study of cortex-like mechanism has the potential to extend our knowledge of brain mechanisms underlying the cognitive analysis and to advance theoretical models of how we recognize face or, more specifically, perceive other people's facial expression in a rich, dynamic, and complex environment, providing a new starting point for improved models of visual cortex-like mechanism.},
	urldate = {2015-06-29},
	journal = {Intell. Neuroscience},
	author = {Fu, Si-Yao and Yang, Guo-Sheng and Kuai, Xin-Kai},
	month = jan,
	year = {2012},
	pages = {19:19--19:19},
	file = {ACM Full Text PDF:E\:\\LQ\\zotero\\storage\\QPPC9NZQ\\Fu 等. - 2012 - A Spiking Neural Network Based Cortex-like Mechani.pdf:application/pdf}
}
@article{vanrullen_surfing_2002,
	title = {Surfing a spike wave down the ventral stream},
	volume = {42},
	issn = {0042-6989},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698902002985},
	doi = {10.1016/S0042-6989(02)00298-5},
	abstract = {Numerous theories of neural processing, often motivated by experimental observations, have explored the computational properties of neural codes based on the absolute or relative timing of spikes in spike trains. Spiking neuron models and theories however, as well as their experimental counterparts, have generally been limited to the simulation or observation of isolated neurons, isolated spike trains, or reduced neural populations. Such theories would therefore seem inappropriate to capture the properties of a neural code relying on temporal spike patterns distributed across large neuronal populations. Here we report a range of computer simulations and theoretical considerations that were designed to explore the possibilities of one such code and its relevance for visual processing. In a unified framework where the relation between stimulus saliency and spike relative timing plays the central role, we describe how the ventral stream of the visual system could process natural input scenes and extract meaningful information, both rapidly and reliably. The first wave of spikes generated in the retina in response to a visual stimulation carries information explicitly in its spatio-temporal structure: the most salient information is represented by the first spikes over the population. This spike wave, propagating through a hierarchy of visual areas, is regenerated at each processing stage, where its temporal structure can be modified by (i) the selectivity of the cortical neurons, (ii) lateral interactions and (iii) top-down attentional influences from higher order cortical areas. The resulting model could account for the remarkable efficiency and rapidity of processing observed in the primate visual system.},
	number = {23},
	urldate = {2015-07-03},
	journal = {Vision Research},
	author = {VanRullen, Rufin and Thorpe, Simon J},
	month = oct,
	year = {2002},
	keywords = {Attention, Neural coding, object recognition, Rank order coding, Spike timing, Visual processing},
	pages = {2593--2615},
	file = {ScienceDirect Full Text PDF:E\:\\LQ\\zotero\\storage\\M5B74Q7E\\VanRullen 和 Thorpe - 2002 - Surfing a spike wave down the ventral stream.pdf:application/pdf;ScienceDirect Snapshot:E\:\\LQ\\zotero\\storage\\8H7VCZ9U\\S0042698902002985.html:text/html}
}
@article{lecun1995convolutional,
	title={Convolutional networks for images, speech, and time series},
	author={LeCun, Yann and Bengio, Yoshua},
	journal={The handbook of brain theory and neural networks},
	volume={3361},
	number={10},
	year={1995}
}
@article{delorme_face_2001,
	title = {Face identification using one spike per neuron: resistance to image degradations},
	volume = {14},
	issn = {0893-6080},
	shorttitle = {Face identification using one spike per neuron},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608001000491},
	doi = {10.1016/S0893-6080(01)00049-1},
	abstract = {The short response latencies of face selective neurons in the inferotemporal cortex impose major constraints on models of visual processing. It appears that visual information must essentially propagate in a feed-forward fashion with most neurons only having time to fire one spike. We hypothesize that flashed stimuli can be encoded by the order of firing of ganglion cells in the retina and propose a neuronal mechanism, that could be related to fast shunting inhibition, to decode such information. Based on these assumptions, we built a three-layered neural network of retino-topically organized neuronal maps. We showed, by using a learning rule involving spike timing dependant plasticity, that neuronal maps in the output layer can be trained to recognize natural photographs of faces. Not only was the model able to generalize to novel views of the same faces, it was also remarkably resistant to image noise and reductions in contrast.},
	number = {6–7},
	urldate = {2015-07-03},
	journal = {Neural Networks},
	author = {Delorme, A. and Thorpe, S. J.},
	month = jul,
	year = {2001},
	keywords = {Computation using spikes, Contrast variations, Face recognition, Feedforward propagation, Image processing, Noise, Rank order coding, visual system},
	pages = {795--803},
	file = {ScienceDirect Full Text PDF:E\:\\LQ\\zotero\\storage\\2HJ94CGM\\Delorme 和 Thorpe - 2001 - Face identification using one spike per neuron re.pdf:application/pdf;ScienceDirect Snapshot:E\:\\LQ\\zotero\\storage\\4SMI2ZPW\\S0893608001000491.html:text/html}
}

@inproceedings{lyons1998coding,
	title={Coding facial expressions with gabor wavelets},
	author={Lyons, Michael and Akamatsu, Shota and Kamachi, Miyuki and Gyoba, Jiro},
	booktitle={Automatic Face and Gesture Recognition, 1998. Proceedings. Third IEEE International Conference on},
	pages={200--205},
	year={1998},
	organization={IEEE}
}
@inproceedings{matsugu2002convolutional,
	title={Convolutional spiking neural network model for robust face detection},
	author={Matsugu, Masakazu and Mori, Katsuhiko and Ishii, Mie and Mitarai, Yusuke},
	booktitle={Neural Information Processing, 2002. ICONIP'02. Proceedings of the 9th International Conference on},
	volume={2},
	pages={660--664},
	year={2002},
	organization={IEEE}
}
@article{camunas2012event,
	title={An event-driven multi-kernel convolution processor module for event-driven vision sensors},
	author={Camunas-Mesa, Luis and Zamarre{\~n}o-Ramos, Carlos and Linares-Barranco, Alejandro and Acosta-Jim{\'e}nez, Antonio J and Serrano-Gotarredona, Teresa and Linares-Barranco, Bernab{\'e}},
	journal={Solid-State Circuits, IEEE Journal of},
	volume={47},
	number={2},
	pages={504--517},
	year={2012},
	publisher={IEEE}
}
@inproceedings{liu2014real,
	title     = {Real-Time Recognition of Dynamic Hand Postures on a Neuromorphic System},
	author    = {Qian Liu and  Steve Furber},
	booktitle = {ICANN 2015: International Conference on Artificial Neural Networks, Amsterdam, The Netherlands },
	year={2015},
	volume    = {1},
	number    = {5},
	pages     = {979},
	publisher = {World Academy of Science, Engineering and Technology}
}

@article{zhao_feedforward_2014,
	title = {Feedforward {Categorization} on {AER} {Motion} {Events} {Using} {Cortex}-{Like} {Features} in a {Spiking} {Neural} {Network}},
	volume = {PP},
	issn = {2162-237X},
	doi = {10.1109/TNNLS.2014.2362542},
	abstract = {This paper introduces an event-driven feedforward categorization system, which takes data from a temporal contrast address event representation (AER) sensor. The proposed system extracts bio-inspired cortex-like features and discriminates different patterns using an AER based tempotron classifier (a network of leaky integrate-and-fire spiking neurons). One of the system’s most appealing characteristics is its event-driven processing, with both input and features taking the form of address events (spikes). The system was evaluated on an AER posture dataset and compared with two recently developed bio-inspired models. Experimental results have shown that it consumes much less simulation time while still maintaining comparable performance. In addition, experiments on the Mixed National Institute of Standards and Technology (MNIST) image dataset have demonstrated that the proposed system can work not only on raw AER data but also on images (with a preprocessing step to convert images into AER events) and that it can maintain competitive accuracy even when noise is added. The system was further evaluated on the MNIST dynamic vision sensor dataset (in which data is recorded using an AER dynamic vision sensor), with testing accuracy of .},
	number = {99},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Zhao, B. and Ding, R. and Chen, S. and Linares-Barranco, B. and Tang, H.},
	year = {2014},
	keywords = {Address event representation (AER), Computer architecture, convolution, event driven, Feature extraction, feedforward categorization, Feedforward neural networks, Kernel, MNIST, Neurons, spiking neural network., Visualization},
	pages = {1--1},
	file = {IEEE Xplore Abstract Record:E\:\\LQ\\zotero\\storage\\UE7EZ2NK\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:E\:\\LQ\\zotero\\storage\\WDRC6U93\\Zhao 等. - 2014 - Feedforward Categorization on AER Motion Events Us.pdf:application/pdf}
}
@article{o2013real,
	title={Real-time classification and sensor fusion with a spiking deep belief network},
	author={O'Connor, Peter and Neil, Daniel and Liu, Shih-Chii and Delbruck, Tobi and Pfeiffer, Michael},
	journal={Frontiers in neuroscience},
	volume={7},
	year={2013},
	publisher={Frontiers Media SA}
}
@article{cao2015spiking,
	title={Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition},
	author={Cao, Yongqiang and Chen, Yang and Khosla, Deepak},
	journal={International Journal of Computer Vision},
	volume={113},
	number={1},
	pages={54--66},
	year={2015},
	publisher={Springer}
}
@article{neftci2013event,
	title={Event-driven contrastive divergence for spiking neuromorphic systems},
	author={Neftci, Emre and Das, Srinjoy and Pedroni, Bruno and Kreutz-Delgado, Kenneth and Cauwenberghs, Gert},
	journal={Frontiers in neuroscience},
	volume={7},
	year={2013},
	publisher={Frontiers Media SA}
}
@article{bichler2012extraction,
	title={Extraction of temporally correlated features from dynamic vision sensors with spike-timing-dependent plasticity},
	author={Bichler, Olivier and Querlioz, Damien and Thorpe, Simon J and Bourgoin, Jean-Philippe and Gamrat, Christian},
	journal={Neural Networks},
	volume={32},
	pages={339--348},
	year={2012},
	publisher={Elsevier}
}
@article{nessler2013bayesian,
	title={Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity},
	author={Nessler, Bernhard and Pfeiffer, Michael and Buesing, Lars and Maass, Wolfgang},
	year={2013}
}
@article{bill2014compound,
	title={A compound memristive synapse model for statistical learning through STDP in spiking neural networks},
	author={Bill, Johannes and Legenstein, Robert},
	journal={Frontiers in neuroscience},
	volume={8},
	year={2014},
	publisher={Frontiers Media SA}
}
@inproceedings{krizhevsky2012imagenet,
	title={Imagenet classification with deep convolutional neural networks},
	author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle={Advances in neural information processing systems},
	pages={1097--1105},
	year={2012}
}
@inproceedings{schuldt2004recognizing,
	title={Recognizing human actions: a local SVM approach},
	author={Sch{\"u}ldt, Christian and Laptev, Ivan and Caputo, Barbara},
	booktitle={Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on},
	volume={3},
	pages={32--36},
	year={2004},
	organization={IEEE}
}
@inproceedings{blank2005actions,
	title={Actions as space-time shapes},
	author={Blank, Moshe and Gorelick, Lena and Shechtman, Eli and Irani, Michal and Basri, Ronen},
	booktitle={Computer Vision, 2005. ICCV 2005. Tenth IEEE International Conference on},
	volume={2},
	pages={1395--1402},
	year={2005},
	organization={IEEE}
}

@inproceedings{Stromatias2015scalable,
  title={Scalable Energy-Efficient, Low-Latency Implementations of Trained Spiking Deep Belief Networks on SpiNNaker},
  author={Stromatias, Evangelos and Neil, Daniel and Galluppi, Francesco and Pfeiffer, Michael and Liu, Shih-Chii and Furber, Steve},
  booktitle={Neural Networks (IJCNN), The 2015 International Joint Conference on},
  pages={to be published},
  year={2015},
  organization={IEEE}
}

@inproceedings{Diehl2015fast,
  title={Fast-Classifying, High-Accuracy Spiking Deep Networks Through Weight and Threshold Balancing},
  author={Diehl, Peter and Neil, Daniel and Binas, Jonathan and Cook, Matthew and Liu, Shih-Chii and Pfeiffer, Michael},
  booktitle={Neural Networks (IJCNN), The 2015 International Joint Conference on},
  pages={to be published},
  year={2015},
  organization={IEEE}
}

@inproceedings{Diehl2015unsupervised,
  title={Unsupervised Learning of Digit Recognition Using Spike-Timing-Dependent Plasticity},
  author={Diehl, Peter and Cook, Matthew},
  booktitle={Neural Networks (IJCNN), The 2015 International Joint Conference on},
  pages={to be published},
  year={2015},
  organization={IEEE}
}