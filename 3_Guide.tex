\section{Guiding Principles}
\label{sec:guide}
\subsection{The Goals}
With this benchmark we hope to (1) promote meaningful comparison among algorithms in the field of neural computation, (2) allow comparison with conventional image recognition methods, (3) provide an assessment of the state of the art in spike-based visual recognition, and (4) help researchers identify future directions and advance the field.
\subsection{Dataset and Testing Protocols Referring the Goals}

%The FERET database was established to support both
%algorithm development and evaluation. Two guiding prin-
%ciples were followed. First, the evaluation of algorithms
%requires a common database of images for both develop-
%ment and testing. In the FERET evaluation, the images in
%the test are from both the development
%and sequestered
%portions of the FERET database. Second, the variety and
%difficulty of the problems defined by the images in the data-
%base must increase incrementally.
%The need to test algorithms against a database is obvious,
%but the development
%function of the database is equally
%important (if less obvious). For the evaluation procedure
%to produce meaningful results, the images in the develop-
%mental portion of the database must resemble those on
%which algorithms are to be tested. The development and
%testing data sets must be similar in both quality and quantity.
%For example, if the test will consist of a gallery of 1000
%individuals,
%it is not appropriate
%for the development
%database to consist of 50 individuals. The algorithms tested
%will be only as good as the database from which they are
%developed. The FERET evaluation procedure followed this
%principle by partitioning the FERET database into the devel-
%opmental and sequestered portions, where the developmen-
%tal portion was representative
%of the sequestered portion
%(details are provided in Section 4.2).
%The other principle is that the problem defined by the
%images in the database must mesh with the current level
%of algorithm development, and the difficulty of the database
%must grow as the sophistication of the algorithms increases.
%As explained in Section 2, if the database defines a problem
%that is too easy, testing the algorithm becomes a mere tuning
%exercise. At the other extreme, if the problem is too far
%beyond the state of the art, the test will not produce any
%meaningful results. To prevent the FERET database from
%becoming stale, we continuously expanded and adjusted the
%database to the state of the art in face recognition.


