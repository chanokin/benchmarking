\section{Performance Evaluation}
\label{sec:eval}

A crucial part of research is reporting results and comparing achievements with other state-of-the-art work. Unfortunately there is no standard way of fulfilling that task, this leads to a hard 
We would like to assist with the following considerations.
\begin{table*}[hbt!]
  \caption{Hardware independent comparison}
  \begin{center}
    \bgroup
    \def\arraystretch{1.5}
    \begin{tabular}{ l  c c c c }
      $ $ &
      \multirow{2}{*}{\begin{minipage}{1.9cm}Preprocessing\end{minipage} }& 
      \begin{minipage}{3.5cm}\centering Network\end{minipage} & 
      \begin{minipage}{3.5cm}\centering Training \end{minipage} & 
      \begin{minipage}{3.5cm}\centering Recognition \end{minipage} \\
      \cline{3-5}
       & 
       & 
      \begin{minipage}{3.5cm}\centering \vspace*{0.1cm} Topology, neuron and synapse model, extra classifier \vspace*{0.1cm} \end{minipage} &
      \begin{minipage}{3.5cm}\centering \vspace*{0.1cm} Methodology, simulation time, sample repetition \end{minipage} & 
      \begin{minipage}{3.5cm}\centering \vspace*{0.1cm} Events/$s$, time/sample, response time, accuracy\end{minipage} \\
      \hline
%contents
      \begin{minipage}{3cm} \cite{Diehl2015unsupervised} \end{minipage} & 
       \centering None &
       \begin{minipage}{3.5cm}\centering Two layers, LI\&F, inhibitory feedback  \end{minipage}& 
       \begin{minipage}{3.5cm}\centering  Unsupervised, exponential STDP, adaptive membrane potential, 150ms silence between samples \end{minipage} & 
       \begin{minipage}{3.5cm}\centering 95\% accuracy \end{minipage}\\
      \begin{minipage}{3cm} \cite{Diehl2015fast}\end{minipage}  & 
      \centering None & 
      \begin{minipage}{3.5cm}\centering ConvNet and fully connected deep net, ReLU neurons (training), I\&F neurons (testing) \end{minipage}& 
      \begin{minipage}{3.5cm}\centering Pre-trained with then converted to SNN, weight normalization \end{minipage}&  
      \begin{minipage}{3.5cm}\centering Simulation time [0.5$s$, 5$s$]; accuracy ConvNet 99.1\%, FCnet 98.6\%\end{minipage}\\
      \begin{minipage}{3cm} Paper 3 [ref]\end{minipage}  & 
      \centering & 
      \begin{minipage}{3.5cm}\centering  \end{minipage}& 
      \begin{minipage}{3.5cm}\centering  \end{minipage}&  
      \begin{minipage}{3.5cm}\centering  \end{minipage}\\
      \begin{minipage}{3cm} Paper 4 [ref]\end{minipage}  
      \centering & 
      \begin{minipage}{3.5cm}\centering  \end{minipage}& 
      \begin{minipage}{3.5cm}\centering  \end{minipage}& 
      \begin{minipage}{3.5cm}\centering  \end{minipage}&
      \begin{minipage}{3.5cm}\centering  \end{minipage}  
    \end{tabular}
    \egroup
  \end{center}
  \label{tb:software_comparison}
\end{table*}

\subsection{Hardware-Independent}
As we are proposing spike based data-sets or a methodology to produce them, it's desirable that the users specify whether they added any further processing either to images or spikes~[\cite{best-practice-nn-img}]. This is important, for example, if we want to use a modified set to test noisy inputs.

A description of the network is most welcome, as it is the basis for the overall performance. Furthermore, sharing this designs may inspire fellow scientists to create new structures that, might take a new point of view to the problem, generating a positive feedback loop where everybody wins. We believe the \emph{network description} should include some of the following elements:
{ 
  \setlength{\leftmargini}{0.3cm}
  \begin{itemize}
    \item[] \hspace*{-0.3cm} \textit{Topology}. \newline
      What are the elements of the network (layers, populations)?
      How are the different elements of the network arranged? Does the arrangement have any physical or biological interpretation? What are the interactions between them? What was the intuition behind this particular topology?
    \item[] \hspace*{-0.3cm} \textit{Neuron model.} \newline
      Does the model have a I\&F behaviour? What particular model was used?
    \item[] \hspace*{-0.3cm} \textit{Synapse model}. \newline
      In terms of synapse, what was the  used? Does the network support short-term and/or long-term plasticity?
    \item[] \hspace*{-0.3cm} \textit{Extra classifier}. \newline
      Some research make use of a non-neural classifier at the output of the NN. How is that integrated into the recognition system? What motivated its use?   
  %\item[]
  \end{itemize}
}



An important distinction to make, we think, is the nature of the \emph{training} procedure. A clear distinction has always been made between supervised, semi-supervised and unsupervised learning. The simulation time each sample is presented, 
Sometimes, repeating samples is necessary, how many times were they repeated, continuous repetition or interleaved

Also, details on the particulars of the applied learning rule (e.g. STDP, BCM), was it modified somehow?

In the testing phase, the characteristics of the \emph{recognition} should include details on the way the samples where presented (e.g. events per simulation time unit, simulation time per sample). An interesting characteristic, particularly for deep networks, is the response time .
Most classification papers report a percentage of accuracy that gives the reader a measure of the correct classifications~[\cite{dietterich1998approximate}]. Some times it might be desirable, for a better understanding of the paper, that a distinction between ambiguous, outliers and incorrect classes is made~[\cite{liu2002performance}]. A very useful piece of information is clear citation of the base-line source, which is almost always there but lost in a sea of references.

%Should we report also incorrect or ambiguous? Could some ``correct'' be masking ambiguous? Were the ambiguous due to noise? Was the noise added on purpose? 


%Traditionally, neural network training has been done using rate-based encoding. As new theories emerge, a


%One the biggest distinctions on learning procedures is whether they were done using some \emph{supervision} or not; making this distinction clear is vastly appreciated. On supervised learning, the label of the data influences to establish categories and connection weights. Unsupervised learning has fewer constraints when it comes to class creation but might be tougher to get right. 

%A number of different classes are expected, this quantity might give an insight onto the network topology and dynamics. A description of the methods used to generate and populate the classes is very helpful for the reader. (e.g. Did we use a statistical measure? Was it a combination of NN with some other algorithms?)




\subsection{[Evangelos Stromatias] Hardware-Specific}


Depending on how neurons, synapses and spike transmission are implemented neuromorphic systems can be categorised as either analogue, digital, or mixed-mode analogue/digital VLSI circuits. Analogue implementations exploit the sub-threshold transistor dynamics to emulate neurons and synapses directly on hardware \citep{giacom} and are more energy-efficient while requiring less area than their digital counterparts \citep{temamanalogdigital}. However, the behaviour of analogue circuits is largely determined during the fabrication process due to transistor mismatch \citep{giacom,analoguemismatch,bernabeDACsynapses}, while their wiring densities render them impractical for large-scale systems. The majority of mixed-mode analogue/digital neuromorphic platforms, such as High Input Count Analog Neural Network (HI-CANN) \citep{Schemmel_etal10}, Neurogrid \citep{Benjamin_etal14}, HiAER-IFAT \citep{gert}, use analogue circuits to emulate neurons and digital packet-based technology to communicate spikes as AER events. This enables reconfigurable connectivity patterns, while the time of spikes is expressed implicitly since typically a spike reaches its destination in less than a millisecond, thus fulfilling the real-time requirement. Digital neuromorphic platforms such as TrueNorth \citep{Merolla08082014} use digital circuits with finite precision to simulate neurons in an event driven manner to minimise the active power dissipation. Neuromorphic systems suffer from model flexibility, since neurons and synapses are fabricated directly on hardware with only a small subset of parameters exposed to the researcher. 

The Spiking Neural Network Architecture, or SpiNNaker, is a biologically inspired, massively-parallel, scalable computing architecture designed by the Advanced Processor Technologies (APT) group at the University of Manchester. SpiNNaker has been optimised to simulate very large-scale spiking neural networks in real-time \citep{spiNNakerProject}. SpiNNaker aims to combine the advantages of conventional computers and neuromorphic hardware by utilising low-power programmable cores and scalable event-driven communications hardware. \textit{\textbf{[ADD AS MUCH DETAILS ABOUT THE SPINNAKER ARCHITECTURE AND SOFTWARE HERE]}}. 

A direct comparison between neuromorphic platforms is not a trivial task due to the different hardware implementation technology. Comparing the performance of each platform in terms of power requirements is an interesting comparison metric especially if targeted for mobile applications and robotics. Some researchers have suggested the use of energy per synaptic event (SE) \citep{Sharp2012110,strometal} as a power metric because the large number of fan in and out of a neuron tend to dominate the total power dissipation during a simulation. Merolla et al. proposed the number of synaptic operations per second per Watt (SOPS/W) \citep{Merolla08082014}. 

Additional comparison metrics could be the precision used to describe the membrane potential of neurons (for the digital platforms), synaptic weights, axonal delays, simulation type (time or event driven) and if the simulation runs in real- or accelerated time.
 
Table~\ref{tb:hardware_comparison} aims to summarise the aforementioned hardware comparison metrics.
 
% mention spinnaker, for this work

%power

%real-time or accelerated

% latency

%Specifying hardware is of utmost importance when comparing computing times and power consumption. Analog or digital or a hybrid system.
%
%Different platforms have special benefits, purely hardware solutions have low power consumption but lack programmability.
%
%New theories, such as Polychronization, suggest that axonal delays are an integral part of the brain's computing mechanisms~[\cite{Izhikevich2005}]. 
%
%Power consumption is a key issue for mobile applications and robotics. A way to measure is to state the number of \emph{Synaptic operations per Watt} that the hardware is capable of.
%
%An important factor to measure performance is the number of \emph{Synaptic events per second}; i.e. rough throughput
%
%A piece of hardware that is difficult to use/program is of little use, thus \emph{front-end support} is
%
%Neural activity highly depends on synapses, specifying what model was used and its precision will impact on the performance.

\begin{table*}
  \caption{Hardware dependent comparison}
  \begin{center}
      \bgroup
      \def\arraystretch{1.4}
    \begin{tabular}{l | c c c c c c c c c}
      $ $ & 
       \begin{minipage}{1.2cm}\centering Hardware approach \end{minipage} & 
       \begin{minipage}{1.3cm}\centering Simulation type \end{minipage} & 
       \begin{minipage}{1.7cm}\centering Programmable \end{minipage} & 
       \begin{minipage}{1cm}\centering Axonal delays \end{minipage} & 
       \begin{minipage}{1cm}\centering Synaptic model \end{minipage} & 
       \begin{minipage}{1.2cm}\centering Synaptic precision \end{minipage} & 
       \begin{minipage}{1.2cm}\centering Energy per SE \end{minipage} & 
       \begin{minipage}{1.4cm}\centering Synaptic ops per Watt \end{minipage} & 
       \begin{minipage}{1.7cm}\centering Programming front-end \end{minipage}  \\
       \hline
       % contents!
       \begin{minipage}{1.8cm}\centering \vspace*{0.1cm} SpiNNaker \citep{strometal} \end{minipage} &Digital& & & & & & 8~nJ &54.27 MSops/W & \\
       \begin{minipage}{1.8cm}\centering \vspace*{0.1cm} TrueNorth \citep{Merolla08082014}\end{minipage} &Digital& & & & & & &46 GSops/W & \\
       \begin{minipage}{1.8cm}\centering \vspace*{0.1cm} Neurogrid \citep{Benjamin_etal14}\end{minipage} &Mixed-mode& & & & & & & & \\
       \begin{minipage}{1.8cm}\centering \vspace*{0.1cm} HI-CANN \citep{Schemmel_etal10}  \end{minipage} &Mixed-mode & & & & & & & & \\
       \begin{minipage}{1.8cm}\centering \vspace*{0.1cm} iAER-IFAT \citep{gert}\end{minipage} &Mixed-mode & & & & & & & & 
       
    \end{tabular}
    \egroup
  \end{center}
  \label{tb:hardware_comparison}
\end{table*}
    
%table summary?
